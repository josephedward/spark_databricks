{"cells":[{"cell_type":"markdown","source":["**Starting a New Databricks Instance **\n- Specifically because of this chapter - could not write out to Databricks filesystem on Wipro instance \n- What was wrong with the Wipro instance? \n- Cannot make SQL connection here, either"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee26f0b1-d1e4-411f-a8f3-e602d67d81a2"}}},{"cell_type":"code","source":["csvFile = spark.read.format(\"csv\")\\\n  .option(\"header\", \"true\")\\\n  .option(\"mode\", \"FAILFAST\")\\\n  .option(\"inferSchema\", \"true\")\\\n  .load(\"/FileStore/tables/2015_summary.csv\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a642fab2-b70d-475b-9845-47aef9722881"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"csvFile","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"DEST_COUNTRY_NAME","nullable":true,"type":"string"},{"metadata":{},"name":"ORIGIN_COUNTRY_NAME","nullable":true,"type":"string"},{"metadata":{},"name":"count","nullable":true,"type":"integer"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%fs\n\nls"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"46a83915-6b4b-48f4-88ae-65909395adda"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"<div class=\"ansiout\">command-2026428415986099:1: error: value cd is not a member of com.databricks.dbutils_v1.DbfsUtils\ndbutils.fs.cd(&quot;dbfs:/FileStore/&quot;, &quot;ls&quot;) // SAFE COMMAND FROM MACRO\n           ^\n</div>","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["csvFile.write.format(\"csv\").mode(\"overwrite\").option(\"sep\", \"\\t\")\\\n  .save(\"/tmp/my-tsv-file.tsv\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe0ed86d-dc5d-45f9-8183-3d3da0357171"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.read.format(\"json\").option(\"mode\", \"FAILFAST\")\\\n  .option(\"inferSchema\", \"true\")\\\n  .load(\"/FileStore/tables/2015_summary.json\").show(5)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b63049a1-1649-4f69-9db9-a31fa1ac0d78"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------------+-------------------+-----+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n|    United States|            Romania|   15|\n|    United States|            Croatia|    1|\n|    United States|            Ireland|  344|\n|            Egypt|      United States|   15|\n|    United States|              India|   62|\n+-----------------+-------------------+-----+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------+-------------------+-----+\nDEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n    United States|            Romania|   15|\n    United States|            Croatia|    1|\n    United States|            Ireland|  344|\n            Egypt|      United States|   15|\n    United States|              India|   62|\n+-----------------+-------------------+-----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["csvFile.write.format(\"json\").mode(\"overwrite\").save(\"/tmp/my-json-file.json\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62662ca6-4940-43b6-b83c-13a212ed28c6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.read.format(\"parquet\")\\\n  .load(\"/FileStore/tables/part_r_00000_1a9822ba_b8fb_4d8e_844a_ea30d0801b9e_gz.parquet\").show(5)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa88250f-8de1-40a0-95b8-cb5941316187"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------------+-------------------+-----+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n|    United States|            Romania|    1|\n|    United States|            Ireland|  264|\n|    United States|              India|   69|\n|            Egypt|      United States|   24|\n|Equatorial Guinea|      United States|    1|\n+-----------------+-------------------+-----+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------+-------------------+-----+\nDEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n    United States|            Romania|    1|\n    United States|            Ireland|  264|\n    United States|              India|   69|\n            Egypt|      United States|   24|\nEquatorial Guinea|      United States|    1|\n+-----------------+-------------------+-----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["csvFile.write.format(\"parquet\").mode(\"overwrite\")\\\n  .save(\"/tmp/my-parquet-file.parquet\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21b8347a-e5d4-4287-b2a2-36e147152431"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.read.format(\"orc\").load(\"/FileStore/tables/part_r_00000_2c4f7d96_e703_4de3_af1b_1441d172c80f_snappy.orc\").show(5)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9201a49-e87d-4cf0-a619-c60634eab93c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------------+-------------------+-----+\n|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n|    United States|            Romania|    1|\n|    United States|            Ireland|  264|\n|    United States|              India|   69|\n|            Egypt|      United States|   24|\n|Equatorial Guinea|      United States|    1|\n+-----------------+-------------------+-----+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------+-------------------+-----+\nDEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+-----------------+-------------------+-----+\n    United States|            Romania|    1|\n    United States|            Ireland|  264|\n    United States|              India|   69|\n            Egypt|      United States|   24|\nEquatorial Guinea|      United States|    1|\n+-----------------+-------------------+-----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["csvFile.write.format(\"orc\").mode(\"overwrite\").save(\"/tmp/my-json-file.orc\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fae1aab3-e031-4d7e-9533-f7c57eb9287a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["driver = \"org.sqlite.JDBC\"\npath = \"/FileStore/tables/my_sqlite.db\"\nurl = \"jdbc:sqlite:\" + path\ntablename = \"flight_info\"\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e2e3632-633d-4c89-b411-256bfcbf73e0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["dbDataFrame = spark.read.format(\"jdbc\").option(\"url\", url)\\\n  .option(\"dbtable\", tablename).option(\"driver\",  driver).load()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"783ecdbf-4adc-41ff-87f8-9bd5955f0578"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2026428415986081&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> dbDataFrame <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>read<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;jdbc&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;url&#34;</span><span class=\"ansi-blue-fg\">,</span> url<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;dbtable&#34;</span><span class=\"ansi-blue-fg\">,</span> tablename<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;driver&#34;</span><span class=\"ansi-blue-fg\">,</span>  driver<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">load</span><span class=\"ansi-blue-fg\">(self, path, format, schema, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    182</span>             <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_spark<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>PythonUtils<span class=\"ansi-blue-fg\">.</span>toSeq<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    183</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 184</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    185</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    186</span>     <span class=\"ansi-blue-fg\">@</span>since<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1.4</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    126</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 127</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    128</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    129</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o639.load.\n: java.sql.SQLException: path to &#39;/FileStore/tables/my_sqlite.db&#39;: &#39;/FileStore&#39; does not exist\n\tat org.sqlite.core.CoreConnection.open(CoreConnection.java:192)\n\tat org.sqlite.core.CoreConnection.&lt;init&gt;(CoreConnection.java:76)\n\tat org.sqlite.jdbc3.JDBC3Connection.&lt;init&gt;(JDBC3Connection.java:24)\n\tat org.sqlite.jdbc4.JDBC4Connection.&lt;init&gt;(JDBC4Connection.java:23)\n\tat org.sqlite.SQLiteConnection.&lt;init&gt;(SQLiteConnection.java:45)\n\tat org.sqlite.JDBC.createConnection(JDBC.java:114)\n\tat org.sqlite.JDBC.connect(JDBC.java:88)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:56)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:226)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:35)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:384)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:373)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:373)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:258)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>","errorSummary":"java.sql.SQLException: path to &#39;/FileStore/tables/my_sqlite.db&#39;: &#39;/FileStore&#39; does not exist","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2026428415986081&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> dbDataFrame <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>read<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;jdbc&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;url&#34;</span><span class=\"ansi-blue-fg\">,</span> url<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;dbtable&#34;</span><span class=\"ansi-blue-fg\">,</span> tablename<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;driver&#34;</span><span class=\"ansi-blue-fg\">,</span>  driver<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">load</span><span class=\"ansi-blue-fg\">(self, path, format, schema, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    182</span>             <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_spark<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>PythonUtils<span class=\"ansi-blue-fg\">.</span>toSeq<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    183</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 184</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    185</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    186</span>     <span class=\"ansi-blue-fg\">@</span>since<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1.4</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    126</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 127</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    128</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    129</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o639.load.\n: java.sql.SQLException: path to &#39;/FileStore/tables/my_sqlite.db&#39;: &#39;/FileStore&#39; does not exist\n\tat org.sqlite.core.CoreConnection.open(CoreConnection.java:192)\n\tat org.sqlite.core.CoreConnection.&lt;init&gt;(CoreConnection.java:76)\n\tat org.sqlite.jdbc3.JDBC3Connection.&lt;init&gt;(JDBC3Connection.java:24)\n\tat org.sqlite.jdbc4.JDBC4Connection.&lt;init&gt;(JDBC4Connection.java:23)\n\tat org.sqlite.SQLiteConnection.&lt;init&gt;(SQLiteConnection.java:45)\n\tat org.sqlite.JDBC.createConnection(JDBC.java:114)\n\tat org.sqlite.JDBC.connect(JDBC.java:88)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:56)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:226)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:35)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:384)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:373)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:373)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:258)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["pgDF = spark.read.format(\"jdbc\")\\\n  .option(\"driver\", \"org.postgresql.Driver\")\\\n  .option(\"url\", \"jdbc:postgresql://database_server\")\\\n  .option(\"dbtable\", \"schema.tablename\")\\\n  .option(\"user\", \"username\").option(\"password\", \"my-secret-password\").load()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84a56427-61b3-4f7e-a5a8-d50f11a4d375"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dbDataFrame.filter(\"DEST_COUNTRY_NAME in ('Anguilla', 'Sweden')\").explain()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1df7dc52-50b8-44a5-808e-6edcfc61c10d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2026428415986083&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>dbDataFrame<span class=\"ansi-blue-fg\">.</span>filter<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;DEST_COUNTRY_NAME in (&#39;Anguilla&#39;, &#39;Sweden&#39;)&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>explain<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;dbDataFrame&#39; is not defined</div>","errorSummary":"<span class=\"ansi-red-fg\">NameError</span>: name &#39;dbDataFrame&#39; is not defined","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2026428415986083&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>dbDataFrame<span class=\"ansi-blue-fg\">.</span>filter<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;DEST_COUNTRY_NAME in (&#39;Anguilla&#39;, &#39;Sweden&#39;)&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>explain<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;dbDataFrame&#39; is not defined</div>"]}}],"execution_count":0},{"cell_type":"code","source":["pushdownQuery = \"\"\"(SELECT DISTINCT(DEST_COUNTRY_NAME) FROM flight_info)\n  AS flight_info\"\"\"\ndbDataFrame = spark.read.format(\"jdbc\")\\\n  .option(\"url\", url).option(\"dbtable\", pushdownQuery).option(\"driver\",  driver)\\\n  .load()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"930a4a3f-a6d3-451a-b6b2-10c7dfaeb029"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2026428415986084&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span>   AS flight_info&#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> dbDataFrame <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>read<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;jdbc&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;url&#34;</span><span class=\"ansi-blue-fg\">,</span> url<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;dbtable&#34;</span><span class=\"ansi-blue-fg\">,</span> pushdownQuery<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;driver&#34;</span><span class=\"ansi-blue-fg\">,</span>  driver<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>   <span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">load</span><span class=\"ansi-blue-fg\">(self, path, format, schema, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    182</span>             <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_spark<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>PythonUtils<span class=\"ansi-blue-fg\">.</span>toSeq<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    183</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 184</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    185</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    186</span>     <span class=\"ansi-blue-fg\">@</span>since<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1.4</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    126</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 127</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    128</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    129</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o679.load.\n: java.sql.SQLException: path to &#39;/FileStore/tables/my_sqlite.db&#39;: &#39;/FileStore&#39; does not exist\n\tat org.sqlite.core.CoreConnection.open(CoreConnection.java:192)\n\tat org.sqlite.core.CoreConnection.&lt;init&gt;(CoreConnection.java:76)\n\tat org.sqlite.jdbc3.JDBC3Connection.&lt;init&gt;(JDBC3Connection.java:24)\n\tat org.sqlite.jdbc4.JDBC4Connection.&lt;init&gt;(JDBC4Connection.java:23)\n\tat org.sqlite.SQLiteConnection.&lt;init&gt;(SQLiteConnection.java:45)\n\tat org.sqlite.JDBC.createConnection(JDBC.java:114)\n\tat org.sqlite.JDBC.connect(JDBC.java:88)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:56)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:226)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:35)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:384)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:373)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:373)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:258)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>","errorSummary":"java.sql.SQLException: path to &#39;/FileStore/tables/my_sqlite.db&#39;: &#39;/FileStore&#39; does not exist","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2026428415986084&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span>   AS flight_info&#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> dbDataFrame <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>read<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;jdbc&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;url&#34;</span><span class=\"ansi-blue-fg\">,</span> url<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;dbtable&#34;</span><span class=\"ansi-blue-fg\">,</span> pushdownQuery<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;driver&#34;</span><span class=\"ansi-blue-fg\">,</span>  driver<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>   <span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">load</span><span class=\"ansi-blue-fg\">(self, path, format, schema, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    182</span>             <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_spark<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>PythonUtils<span class=\"ansi-blue-fg\">.</span>toSeq<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    183</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 184</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    185</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    186</span>     <span class=\"ansi-blue-fg\">@</span>since<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1.4</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    126</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 127</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    128</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    129</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o679.load.\n: java.sql.SQLException: path to &#39;/FileStore/tables/my_sqlite.db&#39;: &#39;/FileStore&#39; does not exist\n\tat org.sqlite.core.CoreConnection.open(CoreConnection.java:192)\n\tat org.sqlite.core.CoreConnection.&lt;init&gt;(CoreConnection.java:76)\n\tat org.sqlite.jdbc3.JDBC3Connection.&lt;init&gt;(JDBC3Connection.java:24)\n\tat org.sqlite.jdbc4.JDBC4Connection.&lt;init&gt;(JDBC4Connection.java:23)\n\tat org.sqlite.SQLiteConnection.&lt;init&gt;(SQLiteConnection.java:45)\n\tat org.sqlite.JDBC.createConnection(JDBC.java:114)\n\tat org.sqlite.JDBC.connect(JDBC.java:88)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:56)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:226)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:35)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:384)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:373)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:373)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:258)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["dbDataFrame = spark.read.format(\"jdbc\")\\\n  .option(\"url\", url).option(\"dbtable\", tablename).option(\"driver\",  driver)\\\n  .option(\"numPartitions\", 10).load()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"02eb2108-b0ab-4901-a050-a940c052df26"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2026428415986085&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> dbDataFrame <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>read<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;jdbc&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span>   <span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;url&#34;</span><span class=\"ansi-blue-fg\">,</span> url<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;dbtable&#34;</span><span class=\"ansi-blue-fg\">,</span> tablename<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;driver&#34;</span><span class=\"ansi-blue-fg\">,</span>  driver<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;numPartitions&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">10</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">load</span><span class=\"ansi-blue-fg\">(self, path, format, schema, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    182</span>             <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_spark<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>PythonUtils<span class=\"ansi-blue-fg\">.</span>toSeq<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    183</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 184</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    185</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    186</span>     <span class=\"ansi-blue-fg\">@</span>since<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1.4</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    126</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 127</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    128</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    129</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o659.load.\n: java.sql.SQLException: path to &#39;/FileStore/tables/my_sqlite.db&#39;: &#39;/FileStore&#39; does not exist\n\tat org.sqlite.core.CoreConnection.open(CoreConnection.java:192)\n\tat org.sqlite.core.CoreConnection.&lt;init&gt;(CoreConnection.java:76)\n\tat org.sqlite.jdbc3.JDBC3Connection.&lt;init&gt;(JDBC3Connection.java:24)\n\tat org.sqlite.jdbc4.JDBC4Connection.&lt;init&gt;(JDBC4Connection.java:23)\n\tat org.sqlite.SQLiteConnection.&lt;init&gt;(SQLiteConnection.java:45)\n\tat org.sqlite.JDBC.createConnection(JDBC.java:114)\n\tat org.sqlite.JDBC.connect(JDBC.java:88)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:56)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:226)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:35)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:384)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:373)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:373)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:258)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>","errorSummary":"java.sql.SQLException: path to &#39;/FileStore/tables/my_sqlite.db&#39;: &#39;/FileStore&#39; does not exist","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2026428415986085&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> dbDataFrame <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>read<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;jdbc&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span>   <span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;url&#34;</span><span class=\"ansi-blue-fg\">,</span> url<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;dbtable&#34;</span><span class=\"ansi-blue-fg\">,</span> tablename<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;driver&#34;</span><span class=\"ansi-blue-fg\">,</span>  driver<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-blue-fg\">.</span>option<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;numPartitions&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">10</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">load</span><span class=\"ansi-blue-fg\">(self, path, format, schema, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    182</span>             <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_spark<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>PythonUtils<span class=\"ansi-blue-fg\">.</span>toSeq<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    183</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 184</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_df<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jreader<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    185</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    186</span>     <span class=\"ansi-blue-fg\">@</span>since<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1.4</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    126</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 127</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    128</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    129</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o659.load.\n: java.sql.SQLException: path to &#39;/FileStore/tables/my_sqlite.db&#39;: &#39;/FileStore&#39; does not exist\n\tat org.sqlite.core.CoreConnection.open(CoreConnection.java:192)\n\tat org.sqlite.core.CoreConnection.&lt;init&gt;(CoreConnection.java:76)\n\tat org.sqlite.jdbc3.JDBC3Connection.&lt;init&gt;(JDBC3Connection.java:24)\n\tat org.sqlite.jdbc4.JDBC4Connection.&lt;init&gt;(JDBC4Connection.java:23)\n\tat org.sqlite.SQLiteConnection.&lt;init&gt;(SQLiteConnection.java:45)\n\tat org.sqlite.JDBC.createConnection(JDBC.java:114)\n\tat org.sqlite.JDBC.connect(JDBC.java:88)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:56)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:226)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:35)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:370)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:384)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:373)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:373)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:258)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["props = {\"driver\":\"org.sqlite.JDBC\"}\npredicates = [\n  \"DEST_COUNTRY_NAME = 'Sweden' OR ORIGIN_COUNTRY_NAME = 'Sweden'\",\n  \"DEST_COUNTRY_NAME = 'Anguilla' OR ORIGIN_COUNTRY_NAME = 'Anguilla'\"]\nspark.read.jdbc(url, tablename, predicates=predicates, properties=props).show()\nspark.read.jdbc(url,tablename,predicates=predicates,properties=props)\\\n  .rdd.getNumPartitions() # 2\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6da855e7-c898-4b81-b7de-e968e3be55a0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["props = {\"driver\":\"org.sqlite.JDBC\"}\npredicates = [\n  \"DEST_COUNTRY_NAME != 'Sweden' OR ORIGIN_COUNTRY_NAME != 'Sweden'\",\n  \"DEST_COUNTRY_NAME != 'Anguilla' OR ORIGIN_COUNTRY_NAME != 'Anguilla'\"]\nspark.read.jdbc(url, tablename, predicates=predicates, properties=props).count()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c161861a-738f-4fac-a1b3-6fa79fb6e281"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["colName = \"count\"\nlowerBound = 0L\nupperBound = 348113L # this is the max count in our database\nnumPartitions = 10\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df6b5cbc-a0db-4d41-877e-f36fac87b9f5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark.read.jdbc(url, tablename, column=colName, properties=props,\n                lowerBound=lowerBound, upperBound=upperBound,\n                numPartitions=numPartitions).count() # 255\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7ded413-5c1c-4808-8b9b-2b8d3d4d2b69"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["newPath = \"jdbc:sqlite://tmp/my-sqlite.db\"\ncsvFile.write.jdbc(newPath, tablename, mode=\"overwrite\", properties=props)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2212958a-7470-44c0-81d8-f83df1ddd540"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark.read.jdbc(newPath, tablename, properties=props).count() # 255\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bea48f5e-4f4a-497f-9d58-824179f58df4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["csvFile.write.jdbc(newPath, tablename, mode=\"append\", properties=props)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c4d52fd0-a6fc-4db2-8732-f023e4e27242"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark.read.jdbc(newPath, tablename, properties=props).count() # 765\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22330cd8-fd76-4b47-aabc-5d40a6f08e28"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\ncsvFile.limit(10).select(\"DEST_COUNTRY_NAME\", \"count\")\\\n  .write.partitionBy(\"count\").text(\"/tmp/five-csv-files2py.csv\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bf35db7e-d308-4938-a122-7a632364260f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["csvFile.limit(10).write.mode(\"overwrite\").partitionBy(\"DEST_COUNTRY_NAME\")\\\n  .save(\"/tmp/partitioned-files.parquet\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a338fe4-2c88-43c9-8155-021c59ea3db6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9137cba9-18a5-4317-b2ce-d199c8a8c229"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Structured_APIs-Chapter_9_Data_Sources","dashboards":[],"language":"python","widgets":{},"notebookOrigID":2026428415986071}},"nbformat":4,"nbformat_minor":0}
